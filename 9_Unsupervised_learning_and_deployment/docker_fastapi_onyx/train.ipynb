{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae8ec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `GarmentClassifier([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `GarmentClassifier([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 1070 which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "NVIDIA GeForce GTX 1070 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the NVIDIA GeForce GTX 1070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 20},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.1+cu128',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"x\"<FLOAT,[1,28,28]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"linear_2\"<FLOAT,[1,10]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"conv1.weight\"<FLOAT,[6,1,5,5]>{TorchTensor(...)},\n",
       "                %\"conv1.bias\"<FLOAT,[6]>{TorchTensor<FLOAT,[6]>(Parameter containing: tensor([-1.8632, -0.8009, -0.0257, -0.0426, -0.2458, -0.0716], requires_grad=True), name='conv1.bias')},\n",
       "                %\"conv2.weight\"<FLOAT,[16,6,5,5]>{TorchTensor(...)},\n",
       "                %\"conv2.bias\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"fc1.weight\"<FLOAT,[120,256]>{TorchTensor(...)},\n",
       "                %\"fc1.bias\"<FLOAT,[120]>{TorchTensor(...)},\n",
       "                %\"fc2.weight\"<FLOAT,[84,120]>{TorchTensor(...)},\n",
       "                %\"fc2.bias\"<FLOAT,[84]>{TorchTensor(...)},\n",
       "                %\"fc3.weight\"<FLOAT,[10,84]>{TorchTensor(...)},\n",
       "                %\"fc3.bias\"<FLOAT,[10]>{TorchTensor<FLOAT,[10]>(Parameter containing: tensor([-0.0327, -0.3417,  0.3544, -0.0659, -0.1239, -0.2826,  0.2765,  0.1370, 0.1115, -0.3740], requires_grad=True), name='fc3.bias')},\n",
       "                %\"val_18\"<INT64,[2]>{Tensor<INT64,[2]>(array([ -1, 256]), name='val_18')},\n",
       "                %\"val_0\"<INT64,[1]>{Tensor<INT64,[1]>(array([0]), name='val_0')}\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_Unsqueeze_1\n",
       "                  %\"val_1\"<FLOAT,[1,1,28,28]> ⬅️ ::Unsqueeze(%\"x\", %\"val_0\"{[0]})\n",
       "             1 |  # node_Conv_2\n",
       "                  %\"val_2\"<FLOAT,[1,6,24,24]> ⬅️ ::Conv(%\"val_1\", %\"conv1.weight\"{...}, %\"conv1.bias\"{[-1.8631598949432373, -0.8009433150291443, -0.025655992329120636, -0.04259829223155975, -0.24580565094947815, -0.07161804288625717]}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             2 |  # node_conv2d\n",
       "                  %\"conv2d\"<FLOAT,[6,24,24]> ⬅️ ::Squeeze(%\"val_2\", %\"val_0\"{[0]})\n",
       "             3 |  # node_relu\n",
       "                  %\"relu\"<FLOAT,[6,24,24]> ⬅️ ::Relu(%\"conv2d\")\n",
       "             4 |  # node_Unsqueeze_5\n",
       "                  %\"val_5\"<FLOAT,[1,6,24,24]> ⬅️ ::Unsqueeze(%\"relu\", %\"val_0\"{[0]})\n",
       "             5 |  # node_MaxPool_6\n",
       "                  %\"val_6\"<FLOAT,[1,6,12,12]> ⬅️ ::MaxPool(%\"val_5\") {storage_order=0, dilations=(1, 1), ceil_mode=0, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), kernel_shape=(2, 2)}\n",
       "             6 |  # node_max_pool2d\n",
       "                  %\"max_pool2d\"<FLOAT,[6,12,12]> ⬅️ ::Squeeze(%\"val_6\", %\"val_0\"{[0]})\n",
       "             7 |  # node_Unsqueeze_8\n",
       "                  %\"val_9\"<FLOAT,[1,6,12,12]> ⬅️ ::Unsqueeze(%\"max_pool2d\", %\"val_0\"{[0]})\n",
       "             8 |  # node_Conv_9\n",
       "                  %\"val_10\"<FLOAT,[1,16,8,8]> ⬅️ ::Conv(%\"val_9\", %\"conv2.weight\"{...}, %\"conv2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             9 |  # node_conv2d_1\n",
       "                  %\"conv2d_1\"<FLOAT,[16,8,8]> ⬅️ ::Squeeze(%\"val_10\", %\"val_0\"{[0]})\n",
       "            10 |  # node_relu_1\n",
       "                  %\"relu_1\"<FLOAT,[16,8,8]> ⬅️ ::Relu(%\"conv2d_1\")\n",
       "            11 |  # node_Unsqueeze_11\n",
       "                  %\"val_12\"<FLOAT,[1,16,8,8]> ⬅️ ::Unsqueeze(%\"relu_1\", %\"val_0\"{[0]})\n",
       "            12 |  # node_MaxPool_12\n",
       "                  %\"val_13\"<FLOAT,[1,16,4,4]> ⬅️ ::MaxPool(%\"val_12\") {storage_order=0, dilations=(1, 1), ceil_mode=0, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(2, 2), kernel_shape=(2, 2)}\n",
       "            13 |  # node_max_pool2d_1\n",
       "                  %\"max_pool2d_1\"<FLOAT,[16,4,4]> ⬅️ ::Squeeze(%\"val_13\", %\"val_0\"{[0]})\n",
       "            14 |  # node_view\n",
       "                  %\"view\"<FLOAT,[1,256]> ⬅️ ::Reshape(%\"max_pool2d_1\", %\"val_18\"{[-1, 256]}) {allowzero=1}\n",
       "            15 |  # node_linear\n",
       "                  %\"linear\"<FLOAT,[1,120]> ⬅️ ::Gemm(%\"view\", %\"fc1.weight\"{...}, %\"fc1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            16 |  # node_relu_2\n",
       "                  %\"relu_2\"<FLOAT,[1,120]> ⬅️ ::Relu(%\"linear\")\n",
       "            17 |  # node_linear_1\n",
       "                  %\"linear_1\"<FLOAT,[1,84]> ⬅️ ::Gemm(%\"relu_2\", %\"fc2.weight\"{...}, %\"fc2.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            18 |  # node_relu_3\n",
       "                  %\"relu_3\"<FLOAT,[1,84]> ⬅️ ::Relu(%\"linear_1\")\n",
       "            19 |  # node_linear_2\n",
       "                  %\"linear_2\"<FLOAT,[1,10]> ⬅️ ::Gemm(%\"relu_3\", %\"fc3.weight\"{...}, %\"fc3.bias\"{[-0.03267591819167137, -0.34174874424934387, 0.35439738631248474, -0.06586664170026779, -0.12387766689062119, -0.28255006670951843, 0.27654460072517395, 0.13701535761356354, 0.1115277037024498, -0.3739825189113617]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            return %\"linear_2\"<FLOAT,[1,10]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_conv1_weight: \"f32[6, 1, 5, 5]\", p_conv1_bias: \"f32[6]\", p_conv2_weight: \"f32[16, 6, 5, 5]\", p_conv2_bias: \"f32[16]\", p_fc1_weight: \"f32[120, 256]\", p_fc1_bias: \"f32[120]\", p_fc2_weight: \"f32[84, 120]\", p_fc2_bias: \"f32[84]\", p_fc3_weight: \"f32[10, 84]\", p_fc3_bias: \"f32[10]\", x: \"f32[1, 28, 28]\"):\n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d: \"f32[6, 24, 24]\" = torch.ops.aten.conv2d.default(x, p_conv1_weight, p_conv1_bias);  x = p_conv1_weight = p_conv1_bias = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/9_Unsupervised_learning_and_deployment/docker_fastapi_onyx/backend/app/garmet_classifier.py:17 in forward, code: x = self.pool(F.relu(self.conv1(x)))\n",
       "                    relu: \"f32[6, 24, 24]\" = torch.ops.aten.relu.default(conv2d);  conv2d = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/nn/modules/pooling.py:226 in forward, code: return F.max_pool2d(\n",
       "                    max_pool2d: \"f32[6, 12, 12]\" = torch.ops.aten.max_pool2d.default(relu, [2, 2], [2, 2]);  relu = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_1: \"f32[16, 8, 8]\" = torch.ops.aten.conv2d.default(max_pool2d, p_conv2_weight, p_conv2_bias);  max_pool2d = p_conv2_weight = p_conv2_bias = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/9_Unsupervised_learning_and_deployment/docker_fastapi_onyx/backend/app/garmet_classifier.py:18 in forward, code: x = self.pool(F.relu(self.conv2(x)))\n",
       "                    relu_1: \"f32[16, 8, 8]\" = torch.ops.aten.relu.default(conv2d_1);  conv2d_1 = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/nn/modules/pooling.py:226 in forward, code: return F.max_pool2d(\n",
       "                    max_pool2d_1: \"f32[16, 4, 4]\" = torch.ops.aten.max_pool2d.default(relu_1, [2, 2], [2, 2]);  relu_1 = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/9_Unsupervised_learning_and_deployment/docker_fastapi_onyx/backend/app/garmet_classifier.py:19 in forward, code: x = x.view(-1, 16 * 4 * 4)\n",
       "                    view: \"f32[1, 256]\" = torch.ops.aten.view.default(max_pool2d_1, [-1, 256]);  max_pool2d_1 = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 120]\" = torch.ops.aten.linear.default(view, p_fc1_weight, p_fc1_bias);  view = p_fc1_weight = p_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/9_Unsupervised_learning_and_deployment/docker_fastapi_onyx/backend/app/garmet_classifier.py:20 in forward, code: x = F.relu(self.fc1(x))\n",
       "                    relu_2: \"f32[1, 120]\" = torch.ops.aten.relu.default(linear);  linear = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_1: \"f32[1, 84]\" = torch.ops.aten.linear.default(relu_2, p_fc2_weight, p_fc2_bias);  relu_2 = p_fc2_weight = p_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/9_Unsupervised_learning_and_deployment/docker_fastapi_onyx/backend/app/garmet_classifier.py:21 in forward, code: x = F.relu(self.fc2(x))\n",
       "                    relu_3: \"f32[1, 84]\" = torch.ops.aten.relu.default(linear_1);  linear_1 = None\n",
       "            \n",
       "                     # File: /home/microslaw/projects/ML-Course-2025-26/.venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_2: \"f32[1, 10]\" = torch.ops.aten.linear.default(relu_3, p_fc3_weight, p_fc3_bias);  relu_3 = p_fc3_weight = p_fc3_bias = None\n",
       "                    return (linear_2,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_conv1_weight: PARAMETER target='conv1.weight'\n",
       "            p_conv1_bias: PARAMETER target='conv1.bias'\n",
       "            p_conv2_weight: PARAMETER target='conv2.weight'\n",
       "            p_conv2_bias: PARAMETER target='conv2.bias'\n",
       "            p_fc1_weight: PARAMETER target='fc1.weight'\n",
       "            p_fc1_bias: PARAMETER target='fc1.bias'\n",
       "            p_fc2_weight: PARAMETER target='fc2.weight'\n",
       "            p_fc2_bias: PARAMETER target='fc2.bias'\n",
       "            p_fc3_weight: PARAMETER target='fc3.weight'\n",
       "            p_fc3_bias: PARAMETER target='fc3.bias'\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear_2: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from backend.app.garmet_classifier import GarmentClassifier\n",
    "import torch\n",
    "\n",
    "model = GarmentClassifier()\n",
    "model.load_state_dict(torch.load(\"../flask_pytorch/model_final\"))\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    args=torch.randn(1, 28, 28).to(\"cpu\"),\n",
    "    f=\"backend/app/model.onnx\",\n",
    "    dynamo=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
