{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision \n",
    "\n",
    "**Framework:** PyTorch \n",
    "\n",
    "**Environment:** Jupyter Notebook, Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Computer Vision with MNIST\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Problem: Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In traditional programming, the developer defines the rules and conditions that the program follows to perform the desired tasks. This approach works well for many problems.\n",
    "\n",
    "However, image classification - which requires the program to correctly identify the class of an image it has never encountered before, is extremely difficult to achieve with traditional programming methods. It is nearly impossible for a programmer to manually prepare rules that will work across the vast diversity of images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Solution: Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning excels at recognizing patterns through a process of trial and error. By training a deep neural network on a sufficient amount of data and providing feedback on its performance during training, the network learns set of rules it needs to correctly interpret and act on new unseen inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 The MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code checks whether a CUDA-enabled GPU is available and, if so, sets the device to use the GPU for computation. Otherwise, it defaults to the CPU.\n",
    "\n",
    "What is CUDA?\n",
    "\n",
    "CUDA (Compute Unified Device Architecture) is a parallel computing platform and programming model developed by NVIDIA. It allows developers to leverage the power of NVIDIA GPUs to accelerate computation-heavy tasks, such as deep learning model training and inference.\n",
    "\n",
    "Difference between CUDA and GPU:\n",
    "\n",
    "GPU (Graphics Processing Unit): Hardware component specialized for parallel processing, initially designed for rendering graphics but highly effective for general-purpose computations.\n",
    "\n",
    "CUDA: Software and programming framework that enables applications to utilize the computational power of NVIDIA GPUs. It provides APIs and tools for writing software that runs on the GPU.\n",
    "\n",
    "In short, CUDA is the bridge that allows software (like PyTorch) to execute on the GPU hardware.\n",
    "\n",
    "Further reading:\n",
    "\n",
    "[What is CUDA?](https://developer.nvidia.com/blog/even-easier-introduction-cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\"./data/\", train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(\"./data/\", train=False, download=True)\n",
    "print(train_dataset[0])\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize_mnist_samples(dataset, num_samples=8):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        image, label = dataset[i]\n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('MNIST Dataset Samples', y=1.02, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "visualize_mnist_samples(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def visualize_first_sample_with_array(dataset):\n",
    "    image, label = dataset[0]\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    axes[0].imshow(image_array, cmap='gray')\n",
    "    axes[0].set_title(f'MNIST Sample Image - Label: {label}')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].axis('off')\n",
    "    table = axes[1].table(cellText=image_array, loc='center', cellLoc='center')\n",
    "    table.scale(0.85, 0.85)\n",
    "    axes[1].set_title('Pixel Values (28x28)')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "visualize_first_sample_with_array(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We succesfully loaded our dataset, now we should convert it to tensor.\n",
    "\n",
    "What is tensor?\n",
    "\n",
    "If a vector is a 1-dimensional array, and a matrix is a 2-dimensional array, a tensor is an n-dimensional array representing any number of dimensions.\n",
    "\n",
    "Why convert data to tensors in Deep Learning?\n",
    "\n",
    "Because tensors are the fundamental data structure used by deep learning frameworks like PyTorch. They efficiently represent and manipulate multi-dimensional data such as images, enabling optimized mathematical operations on CPU and GPU. \n",
    "\n",
    "[More about tensors](https://docs.pytorch.org/docs/stable/tensors.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.v2 as transforms\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "x_0, y_0 = train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When working with deep learning you will often encounter images marked as X and labels marked as Y. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_tensor = transform(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_tensor.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's ToTensor() transform converts a PIL image or a NumPy array with pixel values in the range of [0-255] into a floating-point tensor of shape (C x H x W) with values normalized to the range [0.0, 1.0].\n",
    "\n",
    "For MNIST, which consists of grayscale 28x28 pixel images, ToTensor() will transform each image from a 28x28 pixel format with integer values 0-255 into a 1x28x28 tensor with floating point values between 0.0 and 1.0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving data and models to a GPU is a crucial step in deep learning. While tensors and models default to being stored and computed on the CPU, GPUs offer more efficient parallel processing capabilities that significantly accelerate training and inference.\n",
    "\n",
    "Consistently ensuring that both data and model reside on the same device also prevents runtime errors caused by device mismatches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_tensor_gpu = x_0_tensor.to(device)\n",
    "x_0_tensor_gpu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Build MLP Model\n",
    "\n",
    "A Multi-Layer Perceptron (MLP) is the most basic type of neural network. For MNIST digit classification, we need:\n",
    "\n",
    "1. **Input Layer**: Flattens the 28x28 image into a 784-dimensional vector\n",
    "2. **Hidden Layer**: Layer with neurons to learn patterns\n",
    "3. **Output Layer**: 10 neurons (one for each digit 0-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden1=128, hidden2=64, num_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, hidden1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu1(self.fc1(x))  # 784 -> 128\n",
    "        x = self.relu2(self.fc2(x))  # 128 -> 64\n",
    "        x = self.fc3(x)              # 64 -> 10\n",
    "        return x\n",
    "\n",
    "model = MLP().to(device)\n",
    "print(\"MLP Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "transform = transforms.Compose([transforms.RandomRotation(degrees=15),\n",
    "                               transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\"./data/\", train=True, download=False, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(\"./data/\", train=False, download=False, transform=transform)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Number of batches (train): {len(train_loader)}\")\n",
    "print(f\"Number of batches (test): {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "print(\"Training MNIST classifier...\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataset, device, num_correct=3, num_wrong=2):\n",
    "    model.eval()\n",
    "\n",
    "    correct_samples = []\n",
    "    wrong_samples = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            if len(correct_samples) >= num_correct and len(wrong_samples) >= num_wrong:\n",
    "                break\n",
    "\n",
    "            image, true_label = dataset[i]\n",
    "            output = model(image.unsqueeze(0).to(device))\n",
    "            pred_label = output.argmax(dim=1).item()\n",
    "\n",
    "            if pred_label == true_label and len(correct_samples) < num_correct:\n",
    "                correct_samples.append((image, true_label, pred_label))\n",
    "            elif pred_label != true_label and len(wrong_samples) < num_wrong:\n",
    "                wrong_samples.append((image, true_label, pred_label))\n",
    "\n",
    "    all_samples = wrong_samples + correct_samples\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "    for idx, (image, true_label, pred_label) in enumerate(all_samples):\n",
    "        ax = axes[idx]\n",
    "        ax.imshow(image.squeeze().cpu().numpy(), cmap='gray')\n",
    "\n",
    "        if true_label == pred_label:\n",
    "            ax.set_title(f'True: {true_label}\\nPred: {pred_label}', color='green')\n",
    "        else:\n",
    "            ax.set_title(f'True: {true_label}\\nPred: {pred_label}', color='red')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Model Predictions (Red=Wrong, Green=Correct)', y=1.1, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Convolutional Neural Networks\n",
    "\n",
    "While the MLP achieved good results, it has a fundamental limitation: it treats images as flat vectors, losing spatial information. \n",
    "\n",
    "**CNN** (Convolutional Neural Network) is designed specifically for images:\n",
    "\n",
    "**Why CNN is better for images:**\n",
    "- **Preserves spatial structure**: Understands that nearby pixels are related\n",
    "- **Parameter sharing**: Uses same filters across the image (fewer parameters)\n",
    "- **Translation invariance**: Detects features regardless of position\n",
    "- **Hierarchical learning**: Learns simple features (edges) -> complex features (shapes)\n",
    "\n",
    "**Key components:**\n",
    "- **Convolutional layers**: Apply filters to detect patterns\n",
    "- **Pooling layers**: Reduce spatial dimensions, keep important features\n",
    "- **Fully connected layers**: Final classification based on learned features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 32)\n",
    "        self.fc2 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "cnn_model = CNN().to(device)\n",
    "print(\"CNN Architecture:\")\n",
    "print(cnn_model)\n",
    "\n",
    "mlp_params = sum(p.numel() for p in model.parameters())\n",
    "cnn_params = sum(p.numel() for p in cnn_model.parameters())\n",
    "\n",
    "print(f\"\\nParameter Comparison:\")\n",
    "print(f\"  MLP: {mlp_params:,} parameters\")\n",
    "print(f\"  CNN: {cnn_params:,} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_criterion = nn.CrossEntropyLoss()\n",
    "cnn_optimizer = Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "print(\"Training CNN on MNIST...\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_loss, train_acc = train_epoch(cnn_model, train_loader, cnn_criterion, cnn_optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CNN Model Predictions:\")\n",
    "visualize_predictions(cnn_model, test_dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
