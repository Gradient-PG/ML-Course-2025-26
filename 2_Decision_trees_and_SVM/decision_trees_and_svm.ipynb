{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aacd976c",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms: Decision Trees & SVM\n",
    "\n",
    "## 1. Installing Required Packages\n",
    "\n",
    "First, let's install and import the necessary Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas matplotlib seaborn scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db429d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print(\"All packages installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e489993",
   "metadata": {},
   "source": [
    "## 2. Exploring the Iris Dataset\n",
    "\n",
    "We'll use the famous Iris dataset - it contains measurements of different iris flowers and their species. This is a classic dataset for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d3864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target (species)\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['species'] = [target_names[i] for i in y]\n",
    "\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Features:\", feature_names)\n",
    "print(\"Target classes:\", target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10765a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 rows of our dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistical summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f58721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationships between features\n",
    "\n",
    "NUM_OF_PLOTS = 3 # # HINT: Change if needed\n",
    "plt.figure(figsize=(8, NUM_OF_PLOTS * 4))\n",
    "\n",
    "# Scatter plot: sepal length vs sepal width, colored by species\n",
    "plt.subplot(NUM_OF_PLOTS, 1, 1)\n",
    "for i, species in enumerate(target_names):\n",
    "    plt.scatter(\n",
    "        df.loc[df[\"species\"] == species, \"sepal length (cm)\"],\n",
    "        df.loc[df[\"species\"] == species, \"sepal width (cm)\"],\n",
    "        label=species,\n",
    "        alpha=0.7\n",
    "    )\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Sepal Width')\n",
    "plt.legend()\n",
    "plt.title('Sepal Length vs Sepal Width')\n",
    "\n",
    "# TODO: Try to visualize the others relationships\n",
    "# Uncomment and complete lines below, remember to change NUM_OF_PLOTS variable\n",
    "# for i, species in enumerate(target_names):\n",
    "#     plt.scatter(\n",
    "#         df.loc[df[\"species\"] == species, ...],\n",
    "#         df.loc[df[\"species\"] == species, ...],\n",
    "#         label=species,\n",
    "#         alpha=0.7\n",
    "#     )\n",
    "# plt.xlabel(...)\n",
    "# plt.ylabel(...)\n",
    "# plt.legend()\n",
    "# plt.title(...)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7ccf78",
   "metadata": {},
   "source": [
    "## Correlation matrix\n",
    "\n",
    "### A correlation matrix is a table that shows the correlation coefficients between multiple variables.\n",
    "### Each cell in the matrix shows how strongly two variables are related — values range from -1 to +1:\n",
    "\n",
    "- +1 → perfect positive correlation (they increase together)\n",
    "\n",
    "- -1 → perfect negative correlation (one increases, the other decreases)\n",
    "\n",
    "- 0 → no linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "sns.heatmap(df[feature_names].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Feature Correlations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bbf7ce",
   "metadata": {},
   "source": [
    "## 3. Splitting Data into Training and Test Sets\n",
    "\n",
    "We split our data so we can:\n",
    "- **Train** our model on one part\n",
    "- **Test** its performance on unseen data\n",
    "\n",
    "This helps us check if our model can generalize to new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ef82d",
   "metadata": {},
   "source": [
    "## 4. Training Our Models\n",
    "\n",
    "### Decision Tree Classifier\n",
    "\n",
    "Decision trees make predictions by asking a series of questions about the features. They're like a flowchart!\n",
    "\n",
    "**Key hyperparameters:**\n",
    "- `max_depth`: How deep the tree can grow (controls complexity)\n",
    "- `min_samples_split`: Minimum samples needed to split a node\n",
    "\n",
    "Let's see how different settings affect our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6885dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to experiment with hyperparameters\n",
    "# You can check this page: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "MAX_DEPTH =   # TODO 1: Try to experiment with max_depth\n",
    "MIN_SAMPLES_LEAF =  # TODO 2: Try to experiment with min_samples_leaf\n",
    "# TODO 3: Try to experiment with the others hyperparameters\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Train the model\n",
    "dt = DecisionTreeClassifier(max_depth=MAX_DEPTH, min_samples_leaf=MIN_SAMPLES_LEAF, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracies\n",
    "train_accuracy = accuracy_score(y_train, dt.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, dt.predict(X_test))\n",
    "\n",
    "# Plot the tree\n",
    "plot_tree(dt, feature_names=feature_names, class_names=target_names, filled=True)\n",
    "plt.title(f'Train Acc: {train_accuracy:.3f}, Test Acc: {test_accuracy:.3f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578e6898",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "\n",
    "SVMs find the best \"decision boundary\" that separates different classes with the largest possible margin.\n",
    "\n",
    "**Key hyperparameters:**\n",
    "- `C`: Controls the trade-off between having a wide margin and classifying training points correctly\n",
    "- `kernel`: The type of function used to separate data (linear, polynomial, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf98fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to experiment with hyperparameters\n",
    "# You can check this page: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "C_VALUE =   # TODO 1: Try to experiment with c_calue\n",
    "KERNEL =  # TODO 2: Try to experiment with kernel\n",
    "# TODO 3: Try to experiment with the others hyperparameters\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Train the model\n",
    "svm = SVC(C=C_VALUE, kernel=KERNEL, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracies\n",
    "train_accuracy = accuracy_score(y_train, svm.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, svm.predict(X_test))\n",
    "\n",
    "# For visualization, we'll use only first two features\n",
    "plt.subplot(2, 2, i+1)\n",
    "\n",
    "# Create a mesh to plot decision boundaries\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                        np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "# Train SVM on first two features for visualization\n",
    "svm_vis = SVC(C=C_VALUE, kernel='linear', random_state=42)\n",
    "svm_vis.fit(X_train[:, :2], y_train)\n",
    "Z = svm_vis.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary and margins\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
    "\n",
    "# Plot training points\n",
    "for class_value in range(len(target_names)):\n",
    "    plt.scatter(X_train[y_train == class_value, 0], \n",
    "                X_train[y_train == class_value, 1], \n",
    "                label=target_names[class_value], \n",
    "                alpha=0.8,\n",
    "                edgecolors='black')\n",
    "\n",
    "plt.xlabel('Sepal Length')\n",
    "plt.ylabel('Sepal Width')\n",
    "plt.title(f'Train Acc: {train_accuracy:.3f}, Test Acc: {test_accuracy:.3f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f564dca7",
   "metadata": {},
   "source": [
    "## 5. Evaluating Our Models\n",
    "\n",
    "Let's compare our best models and see how they perform on the test data.\n",
    "\n",
    "We'll use:\n",
    "- **Accuracy**: Percentage of correct predictions\n",
    "- **Confusion Matrix**: Shows which classes are being confused\n",
    "- **Classification Report**: Detailed performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fda706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our final models with optimized parameters\n",
    "best_dt = DecisionTreeClassifier(max_depth=MAX_DEPTH, min_samples_leaf=MIN_SAMPLES_LEAF, random_state=42)\n",
    "best_svm = SVC(C=C_VALUE, kernel=KERNEL, random_state=42)\n",
    "\n",
    "best_dt.fit(X_train, y_train)\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "y_pred_svm = best_svm.predict(X_test)\n",
    "\n",
    "# Calculate accuracies\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(\"=== Model Performance Comparison ===\")\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.3f}\")\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Decision Tree confusion matrix\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names, ax=ax1)\n",
    "ax1.set_title('Decision Tree - Confusion Matrix')\n",
    "ax1.set_xlabel('Predicted')\n",
    "ax1.set_ylabel('Actual')\n",
    "\n",
    "# SVM confusion matrix\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names, ax=ax2)\n",
    "ax2.set_title('SVM - Confusion Matrix')\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
